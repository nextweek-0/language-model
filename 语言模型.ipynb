{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "tpmWhoEyZBrC",
    "outputId": "c0f0cac3-c40f-4764-cf81-d25d14fc7a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iSD3kncwaBBq"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hJTjVIMCazml",
    "outputId": "829f42a9-9046-4b52-ee3a-ec4e828284ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config', 'drive', 'sample_data']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "L1RwejAAa2vW"
   },
   "outputs": [],
   "source": [
    "os.chdir('./drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8qF6LtE7a6tI",
    "outputId": "ae21f26f-6fdf-4125-b531-7ebac716c933"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.shortcut-targets-by-id', 'My Drive', '.Trash']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZvG-GEpObAZ3"
   },
   "outputs": [],
   "source": [
    "os.chdir('./My Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2Ca6dC5LbE21",
    "outputId": "d4ba5f06-c820-4709-f385-a6a7e4b56d22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app', 'drive', 'yuchuli.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N8PJr6n9bHUv"
   },
   "outputs": [],
   "source": [
    "os.chdir('./drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u2rnxE96bO7X",
    "outputId": "91da8b81-da51-4beb-aaf8-5f31592b464d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnn_7', '图像分类', '基于注意力机制的翻译.ipynb', 'yuyanmoxing']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KVtQvqV9bTiz"
   },
   "outputs": [],
   "source": [
    "os.chdir('./yuyanmoxing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LmIbT-ekbYrN",
    "outputId": "4abdafd3-b05d-465d-f348-ad8d394adac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text8', '__MACOSX', '语言模型']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8MeNSa9bdn6l"
   },
   "outputs": [],
   "source": [
    "os.chdir('./text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "GZpRGPH2dslD",
    "outputId": "da85f8b1-66c8-4c93-a1fa-041d7e2d108a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.38.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mtJKXQBld-Qy"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iya_5780ePQn"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "# random.seed(53113)\n",
    "# np.random.seed(53113)\n",
    "# torch.manual_seed(53113)\n",
    "# if USE_CUDA:\n",
    "#     torch.cuda.manual_seed(53113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Nsc1lGFOeyn6"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 650\n",
    "MAX_VOCAB_SIZE = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pMKHr0DzhMjt",
    "outputId": "0bb5975a-d2b1-4bfb-e8ca-153d23d4a76a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text8.zip', 'text8.dev.txt', 'text8.test.txt', 'text8.train.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "jtTIV9ASgMT9",
    "outputId": "995c758d-32a0-4ed8-d353-5b05df56f000"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 50002\n"
     ]
    }
   ],
   "source": [
    "TEXT = torchtext.data.Field(lower=True)\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(path=\".\", \n",
    "    train=\"text8.train.txt\", validation=\"text8.dev.txt\", test=\"text8.test.txt\", text_field=TEXT)\n",
    "TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)\n",
    "print(\"vocabulary size: {}\".format(len(TEXT.vocab)))\n",
    "\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=BATCH_SIZE, device=-1, bptt_len=32, repeat=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "emHws-TQgRKt"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KwTaPSPlljds"
   },
   "outputs": [],
   "source": [
    "it = iter(train_iter)\n",
    "batch = next(it)\n",
    "# print(batch)\n",
    "# batch.numpy()\n",
    "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:,1].data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BbnGb-XzynCb",
    "outputId": "3aed574f-d956-4a21-efe2-136f893b6d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine in pairs and then group into trios of pairs which are the smallest visible units of matter this parallels with the structure of modern atomic theory in which pairs or triplets\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:,1].data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "orgnxNhGyaxW",
    "outputId": "11fa9611-3cb0-4ba6-8ba5-74d5fcc01403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combine'"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[batch.text[:,1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "A08AeMk3gX9E",
    "outputId": "77753ce0-9d3a-4d2c-c7c1-ddcf7ac1eb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6271)\n",
      "tensor(6)\n",
      "tensor(3593)\n",
      "tensor(4)\n",
      "tensor(105)\n",
      "tensor(191)\n",
      "tensor(66)\n",
      "tensor(29094)\n",
      "tensor(3)\n",
      "tensor(3593)\n",
      "tensor(37)\n",
      "tensor(27)\n",
      "tensor(2)\n",
      "tensor(4859)\n",
      "tensor(2320)\n",
      "tensor(1067)\n",
      "tensor(3)\n",
      "tensor(842)\n",
      "tensor(34)\n",
      "tensor(8292)\n",
      "tensor(25)\n",
      "tensor(2)\n",
      "tensor(587)\n",
      "tensor(3)\n",
      "tensor(173)\n",
      "tensor(2151)\n",
      "tensor(214)\n",
      "tensor(6)\n",
      "tensor(37)\n",
      "tensor(3593)\n",
      "tensor(30)\n",
      "tensor(25697)\n"
     ]
    }
   ],
   "source": [
    "for i in batch.text[:,1].data:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rhnu_GzZoJ45"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
    "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "\n",
    "    def init_hidden(self, bsz, requires_grad=True):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros((self.nlayers, bsz, self.nhid), requires_grad=requires_grad),\n",
    "                weight.new_zeros((self.nlayers, bsz, self.nhid), requires_grad=requires_grad))\n",
    "        else:\n",
    "            return weight.new_zeros((self.nlayers, bsz, self.nhid), requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3IEHW2uJhU5r"
   },
   "outputs": [],
   "source": [
    "model = RNNModel(\"LSTM\", VOCAB_SIZE, EMBEDDING_SIZE, EMBEDDING_SIZE, 2, dropout=0.5)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UqQFMMOfhX17"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  it = iter(data)\n",
    "  total_count = 0\n",
    "  with torch.no_grad():\n",
    "    hidden = model.init_hidden(BATCH_SIZE,requires_grad=False)\n",
    "    for i, batch in enumerate(it):\n",
    "      data, target = batch.text, batch.target\n",
    "      if USE_CUDA:\n",
    "        data,target = data.cuda(), target.cuda()\n",
    "      hidden = repackage_hidden(hidden)\n",
    "      with torch.no_grad():\n",
    "        output,hidden = model(data,hidden)\n",
    "      loss = loss_fn(output.view(-1,VOCAB_SIZE),target.view(-1))\n",
    "      total_count += np.multiply(*data.size())\n",
    "      total_loss += loss.item()*np.multiply(*data.size())\n",
    "  loss = total_loss / total_count\n",
    "  model.train()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7jHGU5pt6ebF"
   },
   "outputs": [],
   "source": [
    "# Remove this part\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mj6EYp1x6p2U"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "-cWDNAN-7HZk",
    "outputId": "683889e2-6cb3-4bf3-fa70-6d5a870c4e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0 loss 10.694487571716309\n",
      "best model, val loss: 10.435706189865899\n",
      "epoch 0 iter 1000 loss 6.393221378326416\n",
      "epoch 0 iter 2000 loss 6.211528778076172\n",
      "epoch 0 iter 3000 loss 6.217827796936035\n",
      "epoch 0 iter 4000 loss 5.63140869140625\n",
      "epoch 0 iter 5000 loss 5.8101301193237305\n",
      "epoch 0 iter 6000 loss 5.867305278778076\n",
      "epoch 0 iter 7000 loss 5.732617378234863\n",
      "epoch 0 iter 8000 loss 5.874238014221191\n",
      "epoch 0 iter 9000 loss 5.301486492156982\n",
      "epoch 0 iter 10000 loss 5.932300090789795\n",
      "best model, val loss: 5.258357186724829\n",
      "epoch 0 iter 11000 loss 5.75202751159668\n",
      "epoch 0 iter 12000 loss 5.48629903793335\n",
      "epoch 0 iter 13000 loss 5.359623908996582\n",
      "epoch 0 iter 14000 loss 5.5689873695373535\n",
      "epoch 1 iter 0 loss 5.71110200881958\n",
      "best model, val loss: 5.1006811082026635\n",
      "epoch 1 iter 1000 loss 5.544424533843994\n",
      "epoch 1 iter 2000 loss 5.3732218742370605\n",
      "epoch 1 iter 3000 loss 5.607327938079834\n",
      "epoch 1 iter 4000 loss 5.135415077209473\n",
      "epoch 1 iter 5000 loss 5.469761371612549\n",
      "epoch 1 iter 6000 loss 5.425756454467773\n",
      "epoch 1 iter 7000 loss 5.3661885261535645\n",
      "epoch 1 iter 8000 loss 5.56312894821167\n",
      "epoch 1 iter 9000 loss 4.9881768226623535\n",
      "epoch 1 iter 10000 loss 5.681709289550781\n",
      "best model, val loss: 4.946326484364318\n",
      "epoch 1 iter 11000 loss 5.530114650726318\n",
      "epoch 1 iter 12000 loss 5.252099990844727\n",
      "epoch 1 iter 13000 loss 5.13714075088501\n",
      "epoch 1 iter 14000 loss 5.3443217277526855\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "GRAD_CLIP = 1\n",
    "NUM_EPOCH = 2\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "  model.train()\n",
    "  it = iter(train_iter)\n",
    "  hidden = model.init_hidden(BATCH_SIZE)\n",
    "  for i,batch in enumerate(it):\n",
    "    data,target = batch.text, batch.target\n",
    "    if USE_CUDA:\n",
    "      data,target = data.cuda(),target.cuda()\n",
    "    hidden = repackage_hidden(hidden)\n",
    "    model.zero_grad()\n",
    "    output,hidden = model(data,hidden)\n",
    "    loss = loss_fn(output.view(-1,VOCAB_SIZE),target.view(-1))\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(),GRAD_CLIP)\n",
    "    optimizer.step()\n",
    "    if i % 1000 == 0:\n",
    "      print('epoch',epoch,'iter',i,'loss',loss.item())\n",
    "    if i % 10000 == 0:\n",
    "      val_loss = evaluate(model,val_iter)\n",
    "\n",
    "      if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "        print('best model, val loss:',val_loss)\n",
    "        torch.save(model.state_dict(),'lm-best.th')\n",
    "      else:\n",
    "        scheduler.step()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=learning)\n",
    "      val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XdaxY7Jm-X1U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "语言模型",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
